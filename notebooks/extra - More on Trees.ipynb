{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "np.set_printoptions(precision=3)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tree_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "graphviz.Source(tree_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=cancer.feature_names)\n",
    "graph = graphviz.Source(tree_dot, format=\"png\")\n",
    "graph.render(filename=\"no_pruning\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=1).fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=cancer.feature_names)\n",
    "graph = graphviz.Source(tree_dot, format=\"png\")\n",
    "graph.render(filename=\"max_depth_1\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_leaf_nodes=8).fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=cancer.feature_names)\n",
    "graph = graphviz.Source(tree_dot, format=\"png\")\n",
    "graph.render(filename=\"max_leaf_nodes_8\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_split=50).fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=cancer.feature_names)\n",
    "graph = graphviz.Source(tree_dot, format=\"png\")\n",
    "graph.render(filename=\"min_samples_split_50\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1, 7)}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "param_grid = {'max_depth':range(1, 7)}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=param_grid, cv=StratifiedShuffleSplit(100))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_max_depth', y='mean_train_score', yerr='std_train_score', ax=plt.gca())\n",
    "scores.plot(x='param_max_depth', y='mean_test_score', yerr='std_test_score', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_max_depth', y=['mean_train_score', 'mean_test_score'], ax=plt.gca())\n",
    "plt.legend(loc=(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_leaf_nodes':range(2, 20)}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=param_grid, cv=StratifiedShuffleSplit(100, random_state=1))\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_max_leaf_nodes', y=['mean_train_score', 'mean_test_score'], ax=plt.gca())\n",
    "plt.legend(loc=(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_max_leaf_nodes', y='mean_train_score', yerr='std_train_score', ax=plt.gca())\n",
    "scores.plot(x='param_max_leaf_nodes', y='mean_test_score', yerr='std_test_score', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_dot = export_graphviz(grid.best_estimator_, out_file=None, feature_names=cancer.feature_names)\n",
    "graph = graphviz.Source(tree_dot, format=\"png\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ram_prices = pd.read_csv(\"ram_price.csv\")\n",
    "\n",
    "plt.semilogy(ram_prices.date, ram_prices.price)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price in $/Mbyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Use historical data to forecast prices after the year 2000\n",
    "data_train = ram_prices[ram_prices.date < 2000]\n",
    "data_test = ram_prices[ram_prices.date >= 2000]\n",
    "\n",
    "# predict prices based on date:\n",
    "X_train = data_train.date[:, np.newaxis]\n",
    "# we use a log-transform to get a simpler relationship of data to target\n",
    "y_train = np.log(data_train.price)\n",
    "\n",
    "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogy(data_train.date, data_train.price, label=\"Training data\", c='k')\n",
    "plt.semilogy(data_test.date, data_test.price, label=\"Test data\")\n",
    "plt.semilogy(data_train.date, np.exp(tree.predict(X_train)), '--', label=\"Tree prediction\")\n",
    "plt.semilogy(data_train.date, np.exp(linear_reg.predict(X_train)), '--', label=\"Linear prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = ram_prices.date[:, np.newaxis]\n",
    "plt.semilogy(data_train.date, data_train.price, label=\"Training data\", c='k')\n",
    "plt.semilogy(data_test.date, data_test.price, label=\"Test data\")\n",
    "plt.semilogy(ram_prices.date, np.exp(tree.predict(X_all)), '--', label=\"Tree prediction\")\n",
    "plt.semilogy(ram_prices.date, np.exp(linear_reg.predict(X_all)), '--', label=\"Linear prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, stratify=iris.target, random_state=0)\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=6).fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=iris.feature_names)\n",
    "graphviz.Source(tree_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, stratify=iris.target, random_state=1)\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=6).fit(X_train, y_train)\n",
    "tree_dot = export_graphviz(tree, out_file=None, feature_names=iris.feature_names)\n",
    "graphviz.Source(tree_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.barh(range(4), tree.feature_importances_)\n",
    "plt.yticks(range(4), iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(noise=.2, random_state=18) # carefully picked random state for illustration\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "voting = VotingClassifier([('logreg', LogisticRegression(C=100)),\n",
    "                           ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))],\n",
    "                         voting='soft')\n",
    "voting.fit(X_train, y_train)\n",
    "lr, tree = voting.estimators_\n",
    "print((\"{:.2f} \" * 3).format(voting.score(X_test, y_test),\n",
    "                             lr.score(X_test, y_test), tree.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lin = np.linspace(X_train[:, 0].min() - .5, X_train[:, 0].max() + .5, 100)\n",
    "y_lin = np.linspace(X_train[:, 1].min() - .5, X_train[:, 1].max() + .5, 100)\n",
    "x_grid, y_grid = np.meshgrid(x_lin, y_lin)\n",
    "X_grid = np.c_[x_grid.ravel(), y_grid.ravel()]\n",
    "# transform produces individual probabilities\n",
    "lr_probs, tree_probs =  voting.transform(X_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, subplot_kw={'xticks': (()), 'yticks': (())}, figsize=(5, 2))\n",
    "for prob, ax in zip([lr_probs, tree_probs, lr_probs + tree_probs], axes.ravel()):\n",
    "    ax.contourf(x_grid, y_grid, prob[:, 1].reshape(x_grid.shape), alpha=.4, cmap='bwr')\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting.estimators_[0].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting.estimators_[1].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, stratify=digits.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=True)\n",
    "estimator_range = range(1, 100, 5)\n",
    "for n_estimators in estimator_range:\n",
    "    rf.n_estimators = n_estimators\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_scores.append(rf.score(X_train, y_train))\n",
    "    test_scores.append(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(estimator_range, test_scores, label=\"train scores\")\n",
    "plt.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "oob_scores = []\n",
    "\n",
    "feature_range = range(1, 64, 5)\n",
    "for max_features in feature_range:\n",
    "    rf = RandomForestClassifier(max_features=max_features, oob_score=True, n_estimators=200, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_scores.append(rf.score(X_train, y_train))\n",
    "    test_scores.append(rf.score(X_test, y_test))\n",
    "    oob_scores.append(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(feature_range, test_scores, label=\"test scores\")\n",
    "plt.plot(feature_range, oob_scores, label=\"oob_scores scores\")\n",
    "plt.plot(feature_range, train_scores, label=\"train scores\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"max_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, stratify=iris.target, random_state=1)\n",
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.barh(range(4), rf.feature_importances_)\n",
    "plt.yticks(range(4), iris.feature_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, stratify=iris.target, random_state=0)\n",
    "gbrt = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "gbrt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# illustration on synthetic moon data\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(noise=.2, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "gbrt = GradientBoostingClassifier(max_depth=2, n_estimators=10, learning_rate=.2, random_state=0).fit(X_train, y_train)\n",
    "gbrt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a grid for plotting decision functions...\n",
    "x_lin = np.linspace(X_train[:, 0].min() - .5, X_train[:, 0].max() + .5, 100)\n",
    "y_lin = np.linspace(X_train[:, 1].min() - .5, X_train[:, 1].max() + .5, 100)\n",
    "x_grid, y_grid = np.meshgrid(x_lin, y_lin)\n",
    "X_grid = np.c_[x_grid.ravel(), y_grid.ravel()]\n",
    "\n",
    "probs = [x for x in gbrt.staged_predict_proba(X_grid)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, subplot_kw={'xticks': (()), 'yticks': (())})\n",
    "for prob, ax in zip(probs, axes.ravel()):\n",
    "    ax.contourf(x_grid, y_grid, prob[:, 1].reshape(x_grid.shape), alpha=.4, cmap='bwr')\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr', s=10)\n",
    "fig.suptitle(\"GradientBostingClassifier(max_depth=2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [.2, .1, .05, .02, .01, .001]}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores.plot(x='param_learning_rate', y='mean_train_score', yerr='std_train_score', ax=plt.gca())\n",
    "scores.plot(x='param_learning_rate', y='mean_test_score', yerr='std_test_score', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "gbrt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [.5, .2, .1, .05, .02, .01, .001]}\n",
    "grid = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "scores.plot(x='param_learning_rate', y='mean_train_score', yerr='std_train_score', ax=plt.gca())\n",
    "scores.plot(x='param_learning_rate', y='mean_test_score', yerr='std_test_score', ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbrt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(gbrt.feature_importances_)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "gbrt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "fig, axs = plot_partial_dependence(gbrt, X_train, np.argsort(gbrt.feature_importances_)[-6:],\n",
    "                                       feature_names=boston.feature_names,\n",
    "                                       n_jobs=3, grid_resolution=50)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(gbrt, X_train, [np.argsort(gbrt.feature_importances_)[-2:]],\n",
    "                                   feature_names=boston.feature_names,\n",
    "\n",
    "                                   n_jobs=3, grid_resolution=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, stratify=iris.target, random_state=0)\n",
    "gbrt = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "gbrt.score(X_test, y_test)\n",
    "\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "for i in range(3):\n",
    "    fig, axs = plot_partial_dependence(gbrt, X_train, range(4), n_cols=4,\n",
    "                                       feature_names=iris.feature_names, grid_resolution=50, label=i,\n",
    "                                       figsize=(8, 2))\n",
    "    fig.suptitle(iris.target_names[i])\n",
    "    for ax in axs: ax.set_xticks(())\n",
    "    for ax in axs[1:]: ax.set_ylabel(\"\")\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
